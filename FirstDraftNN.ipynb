{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferential Voting Neural Net: ***A First Draft***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the basic imports and devices to train the net on the gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "not_handled_pref_data = True\n",
    "if not_handled_pref_data:\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "    trainset = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "    testset = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Primary and 2CP Vote Data For Polling Booth (Currently just NSW) \n",
    "\n",
    "Extracting data from the csv file and dumping into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def getrows(url):\n",
    "    # Row Stuff ## Extract data into a big array and then combine booths.\n",
    "    row_count = 0\n",
    "    rows = [] # Will store the data as needed.\n",
    "    with open(url,newline='') as primaryvotesFile:\n",
    "        reader  = csv.reader(primaryvotesFile, delimiter=',', quotechar='\"')\n",
    "        for row in reader:\n",
    "            rows.append(row)\n",
    "            row_count += 1\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing rows to get a each row as [PollingID, PartyIdentifier, Votes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rows of the csv into important data\n",
    "# From CSV Format\n",
    "def parseData(rows):\n",
    "    POLLPLACEID = 3\n",
    "    CANDID = 5\n",
    "    PARTYAB = 11\n",
    "    PARTYNAME = 12\n",
    "    VOTES = 13\n",
    "\n",
    "    parsedData = []\n",
    "    for row in rows[2:]: # Slice off the two overhead lines\n",
    "        accepting = True\n",
    "        data = []\n",
    "        ## data = [PollingID, PartyIdentifier, Votes]\n",
    "        data.append(row[3])\n",
    "        # Check that the PARTYAB exist\n",
    "        if row[PARTYAB] != None and row[PARTYAB] != '':\n",
    "            data.append(row[PARTYAB])\n",
    "        # If no PARTYAB exists, check if this is the informal vote at given polling booth\n",
    "        elif row[PARTYNAME] == \"Informal\":\n",
    "            data.append(\"INFORMAL\")\n",
    "        # If not informal and no PARTYAB try the PARTYNAME. ''.join(row[PARTYNAME].split()) removes whitespace\n",
    "        elif row[PARTYNAME] != None and row[PARTYNAME] != '':\n",
    "            data.append(''.join(row[PARTYNAME].split()))\n",
    "        # If no PARTYAB and no PARTYNAME use candidate ID\n",
    "        else:\n",
    "            data.append(row[CANDID])\n",
    "\n",
    "        data.append(row[VOTES])\n",
    "\n",
    "        if accepting:\n",
    "            parsedData.append(data)\n",
    "    return parsedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformatting the data into a list where each element represents the primary/2CP votes at a given pollingPlace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineData(parsedData):\n",
    "    combinedData = []\n",
    "    for idx, data_entry in enumerate(parsedData):\n",
    "        try:\n",
    "            pollingplace = int(data_entry[0])\n",
    "            # Check The Current List\n",
    "            if combinedData[-1]['pollingID'] == pollingplace:\n",
    "                combinedData[-1][data_entry[1]] = int(data_entry[2])\n",
    "            else:\n",
    "                newdict = {'pollingID':pollingplace,data_entry[1]:int(data_entry[2])}\n",
    "                combinedData.append(newdict)\n",
    "        except IndexError:\n",
    "            newdict = {'pollingID':pollingplace,data_entry[1]:int(data_entry[2])}\n",
    "            combinedData.append(newdict)\n",
    "    return combinedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try0(x, key):\n",
    "    try:\n",
    "        return x[key]\n",
    "    except KeyError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(combinedData):\n",
    "    Xs = []\n",
    "    for x in combinedData:\n",
    "        others = 0\n",
    "        for index, (key,value) in enumerate(x.items()):\n",
    "            if key not in [\"LP\",\"NP\",\"ALP\",\"GRN\",\"IND\",\"ON\",\"UAPP\",\"pollingID\",\"INFORMAL\"]:\n",
    "                others += value\n",
    "        X = [\n",
    "            try0(x,\"LP\"),\n",
    "            try0(x,\"NP\"),\n",
    "            try0(x,\"ALP\"),\n",
    "            try0(x,\"GRN\"),\n",
    "            try0(x,\"ON\"),\n",
    "            try0(x,\"UAPP\"),\n",
    "            try0(x,\"IND\"),\n",
    "            others,\n",
    "            try0(x,\"INFORMAL\"),\n",
    "        ]\n",
    "        Xs.append(X)\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(Xs):\n",
    "    newXs = []\n",
    "    for x in Xs:\n",
    "        if sum(x)!= 0:\n",
    "            newx = [value/sum(x) for value in x]\n",
    "        else:\n",
    "            newx = x\n",
    "        newXs.append(newx)\n",
    "    return newXs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = getrows('NSWPrimaryPollingPlace.csv')\n",
    "parsedData = parseData(rows)\n",
    "combinedData = combineData(parsedData)\n",
    "Xs = convert(combinedData)\n",
    "Xs = normalise(Xs)\n",
    "Xs = torch.tensor(Xs) # Convert to tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = getrows('NSW2CPPollingPlace.csv')\n",
    "parsedData = parseData(rows)\n",
    "combinedData = combineData(parsedData)\n",
    "ys = convert(combinedData)\n",
    "ys = normalise(ys)\n",
    "ys = torch.tensor(ys) # Convert to tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2594\n",
      "288\n",
      "2594\n",
      "288\n"
     ]
    }
   ],
   "source": [
    "VAL_PCT = 0.1\n",
    "val_size = int(len(Xs)*VAL_PCT)\n",
    "\n",
    "train_X = Xs[:-val_size]\n",
    "train_y = ys[:-val_size]\n",
    "\n",
    "test_X = Xs[-val_size:]\n",
    "test_y = ys[-val_size:]\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))\n",
    "print(len(train_y))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(len(Xs[0]), 64) \n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, len(ys[0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=9, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=9, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net= Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 360.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0. Loss: 0.04027148336172104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 324.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1. Loss: 0.019344478845596313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 333.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2. Loss: 0.016874486580491066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 100\n",
    "loss_function = nn.MSELoss()\n",
    "def train(net):\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0,len(train_X),BATCH_SIZE)):\n",
    "            batch_X = train_X[i:i+BATCH_SIZE].view(-1,len(Xs[0]))\n",
    "            batch_y = train_y[i:i+BATCH_SIZE]\n",
    "            \n",
    "            batch_X, batch_y = batch_X.to(device),batch_y.to(device)\n",
    "            \n",
    "            net.zero_grad()\n",
    "            outputs = net(batch_X)\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch:{epoch}. Loss: {loss}\")\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3070, 0.1195, 0.4603, 0.0175, 0.0130, 0.0193, 0.0388, 0.0169, 0.0075]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(net(Xs[0].view(-1,len(Xs[0])).to(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\patri\\Documents\\Git\\PrefVotingNN\\FirstDraftNN.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/patri/Documents/Git/PrefVotingNN/FirstDraftNN.ipynb#ch0000020?line=2'>3</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/patri/Documents/Git/PrefVotingNN/FirstDraftNN.ipynb#ch0000020?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/patri/Documents/Git/PrefVotingNN/FirstDraftNN.ipynb#ch0000020?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m testset:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/patri/Documents/Git/PrefVotingNN/FirstDraftNN.ipynb#ch0000020?line=5'>6</a>\u001b[0m         X,y \u001b[39m=\u001b[39m data\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/patri/Documents/Git/PrefVotingNN/FirstDraftNN.ipynb#ch0000020?line=6'>7</a>\u001b[0m         output \u001b[39m=\u001b[39m net(X\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m28\u001b[39m)\u001b[39m.\u001b[39mto(device))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testset' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's test our data!\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test:\n",
    "        X,y = data\n",
    "        output = net(X.view(-1,28*28).to(device))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total +=1 \n",
    "print(\"Accuracy: \",round(correct/total,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
