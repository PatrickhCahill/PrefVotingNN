{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferential Voting Neural Net: ***A First Draft***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the basic imports and devices to train the net on the gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "not_handled_pref_data = False\n",
    "if not_handled_pref_data:\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "    trainset = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "    testset = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Primary and 2CP Vote Data For Polling Booth (Currently just NSW) \n",
    "\n",
    "Extracting data from the csv file and dumping into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def getrows(url):\n",
    "    # Row Stuff ## Extract data into a big array and then combine booths.\n",
    "    row_count = 0\n",
    "    rows = [] # Will store the data as needed.\n",
    "    with open(url,newline='') as primaryvotesFile:\n",
    "        reader  = csv.reader(primaryvotesFile, delimiter=',', quotechar='\"')\n",
    "        for row in reader:\n",
    "            rows.append(row)\n",
    "            row_count += 1\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing rows to get a each row as [PollingID, PartyIdentifier, Votes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rows of the csv into important data\n",
    "# From CSV Format\n",
    "def parseData(rows):\n",
    "    POLLPLACEID = 3\n",
    "    CANDID = 5\n",
    "    PARTYAB = 11\n",
    "    PARTYNAME = 12\n",
    "    VOTES = 13\n",
    "\n",
    "    parsedData = []\n",
    "    for row in rows[2:]: # Slice off the two overhead lines\n",
    "        accepting = True\n",
    "        data = []\n",
    "        ## data = [PollingID, PartyIdentifier, Votes]\n",
    "        data.append(row[3])\n",
    "        # Check that the PARTYAB exist\n",
    "        if row[PARTYAB] != None and row[PARTYAB] != '':\n",
    "            data.append(row[PARTYAB])\n",
    "        # If no PARTYAB exists, check if this is the informal vote at given polling booth\n",
    "        elif row[PARTYNAME] == \"Informal\":\n",
    "            data.append(\"INFORMAL\")\n",
    "        # If not informal and no PARTYAB try the PARTYNAME. ''.join(row[PARTYNAME].split()) removes whitespace\n",
    "        elif row[PARTYNAME] != None and row[PARTYNAME] != '':\n",
    "            data.append(''.join(row[PARTYNAME].split()))\n",
    "        # If no PARTYAB and no PARTYNAME use candidate ID\n",
    "        else:\n",
    "            data.append(row[CANDID])\n",
    "\n",
    "        data.append(row[VOTES])\n",
    "\n",
    "        if accepting:\n",
    "            parsedData.append(data)\n",
    "    return parsedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformatting the data into a list where each element represents the primary/2CP votes at a given pollingPlace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineData(parsedData):\n",
    "    combinedData = []\n",
    "    for idx, data_entry in enumerate(parsedData):\n",
    "        try:\n",
    "            pollingplace = int(data_entry[0])\n",
    "            # Check The Current List\n",
    "            if combinedData[-1]['pollingID'] == pollingplace:\n",
    "                combinedData[-1][data_entry[1]] = int(data_entry[2])\n",
    "            else:\n",
    "                newdict = {'pollingID':pollingplace,data_entry[1]:int(data_entry[2])}\n",
    "                combinedData.append(newdict)\n",
    "        except IndexError:\n",
    "            newdict = {'pollingID':pollingplace,data_entry[1]:int(data_entry[2])}\n",
    "            combinedData.append(newdict)\n",
    "    return combinedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try0(x, key):\n",
    "    try:\n",
    "        return x[key]\n",
    "    except KeyError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(combinedData):\n",
    "    Xs = []\n",
    "    for x in combinedData:\n",
    "        others = 0\n",
    "        for index, (key,value) in enumerate(x.items()):\n",
    "            if key not in [\"LP\",\"NP\",\"ALP\",\"GRN\",\"IND\",\"ON\",\"UAPP\",\"AJP\",\"pollingID\",\"INFORMAL\"]:\n",
    "                others += value\n",
    "        X = [\n",
    "            try0(x,\"LP\"),\n",
    "            try0(x,\"NP\"),\n",
    "            try0(x,\"ALP\"),\n",
    "            try0(x,\"GRN\"),\n",
    "            try0(x,\"ON\"),\n",
    "            try0(x,\"UAPP\"),\n",
    "            try0(x,\"AJP\"),\n",
    "            try0(x,\"IND\"),\n",
    "            others,\n",
    "            try0(x,\"INFORMAL\"),\n",
    "        ]\n",
    "        Xs.append(X)\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(Xs):\n",
    "    newXs = []\n",
    "    for x in Xs:\n",
    "        if sum(x)!= 0:\n",
    "            newx = [value/sum(x) for value in x]\n",
    "        else:\n",
    "            newx = x\n",
    "        newXs.append(newx)\n",
    "    return newXs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = getrows('PrimaryPollingPlace.csv')\n",
    "parsedData = parseData(rows)\n",
    "combinedData = combineData(parsedData)\n",
    "Xs = convert(combinedData)\n",
    "Xs = normalise(Xs)\n",
    "Xs = torch.tensor(Xs) # Convert to tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3016, 0.0000, 0.3807, 0.1668, 0.0246, 0.0278, 0.0000, 0.0642, 0.0000,\n",
       "        0.0342])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = getrows('2CPPollingPlace.csv')\n",
    "parsedData = parseData(rows)\n",
    "combinedData = combineData(parsedData)\n",
    "ys = convert(combinedData)\n",
    "ys = normalise(ys)\n",
    "ys = torch.tensor(ys) # Convert to tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "balancing = False\n",
    "if balancing:\n",
    "    winners = {0:0,\n",
    "                1:0,\n",
    "                2:0,\n",
    "                3:0,\n",
    "                4:0,\n",
    "                5:0,\n",
    "                6:0,\n",
    "                7:0,\n",
    "                8:0,\n",
    "                9:0}\n",
    "    for they in ys:\n",
    "        y = they.numpy()\n",
    "        winner = np.where(y==max(y))[0][0]\n",
    "        \n",
    "        winners[winner] += 1\n",
    "\n",
    "    total = sum(winners.values())\n",
    "    for key in winners.keys():\n",
    "        try: \n",
    "            winners[key] = round(total/(winners[key]))\n",
    "        except ZeroDivisionError:\n",
    "            winners[key] = 0\n",
    "\n",
    "    newXs = []\n",
    "    newys = []\n",
    "    for index, y in enumerate(ys):\n",
    "        numpyy = y.numpy()\n",
    "        winner = np.where(numpyy==max(numpyy))[0][0]\n",
    "        newXs += [Xs[index].numpy()]*winners[winner]\n",
    "        newys += [y.numpy()]*winners[winner]\n",
    "\n",
    "    Xs = torch.tensor(newXs)\n",
    "    ys = torch.tensor(newys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8479\n",
      "8479\n",
      "tensor([0.3016, 0.0000, 0.3807, 0.1668, 0.0246, 0.0278, 0.0000, 0.0642, 0.0000,\n",
      "        0.0342])\n",
      "tensor([0.3787, 0.0000, 0.6213, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n"
     ]
    }
   ],
   "source": [
    "print(len(Xs))\n",
    "print(len(ys))\n",
    "print(Xs[0])\n",
    "print(ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3787, 0.0000, 0.6213, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n",
      "{0: 0, 1: 0, 2: 1, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n"
     ]
    }
   ],
   "source": [
    "winners = {0:0,\n",
    "            1:0,\n",
    "            2:0,\n",
    "            3:0,\n",
    "            4:0,\n",
    "            5:0,\n",
    "            6:0,\n",
    "            7:0,\n",
    "            8:0,\n",
    "            9:0}\n",
    "for they in ys:\n",
    "    print(they)\n",
    "    y = they.numpy()\n",
    "    winner = np.where(y==max(y))[0][0]\n",
    "    \n",
    "    winners[winner] += 1\n",
    "    break\n",
    "print(winners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7632\n",
      "847\n",
      "7632\n",
      "847\n"
     ]
    }
   ],
   "source": [
    "VAL_PCT = 0.1\n",
    "val_size = int(len(Xs)*VAL_PCT)\n",
    "\n",
    "train_X = Xs[:-val_size]\n",
    "train_y = ys[:-val_size]\n",
    "\n",
    "test_X = Xs[-val_size:]\n",
    "test_y = ys[-val_size:]\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))\n",
    "print(len(train_y))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(len(Xs[0]), 64) \n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, len(ys[0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=10, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net= Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:18<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 100\n",
    "loss_function = nn.MSELoss()\n",
    "def train(net):\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        for i in range(0,len(train_X),BATCH_SIZE):\n",
    "            batch_X = train_X[i:i+BATCH_SIZE].view(-1,len(Xs[0]))\n",
    "            batch_y = train_y[i:i+BATCH_SIZE]\n",
    "            \n",
    "            batch_X, batch_y = batch_X.to(device),batch_y.to(device)\n",
    "            \n",
    "            net.zero_grad()\n",
    "            outputs = net(batch_X)\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # print(f\"Epoch:{epoch}. Loss: {loss}\")\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.448, 0.0, 0.546, 0.006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def printpred(pred):\n",
    "    pred = torch.tensor(pred)\n",
    "    atensor = net(pred.view(-1,len(pred)).to(device))[0]\n",
    "    alist = [round(float(x),3) for x in atensor]\n",
    "    print(alist)\n",
    "printpred([0.377,0,0.273,0.272,0.022,0.019,0.02,0.0,0.017,0.021])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rows of the csv into important data\n",
    "# From CSV Format\n",
    "def parseDataDivision(rows):\n",
    "    DIVISIONID = 1\n",
    "    CANDID = 3\n",
    "    PARTYAB = 9\n",
    "    PARTYNAME = 10\n",
    "    VOTES = 16\n",
    "\n",
    "    parsedData = []\n",
    "    for row in rows[2:]: # Slice off the two overhead lines\n",
    "        accepting = True\n",
    "        data = []\n",
    "        ## data = [PollingID, PartyIdentifier, Votes]\n",
    "        data.append(row[DIVISIONID])\n",
    "        # Check that the PARTYAB exist\n",
    "        if row[PARTYAB] != None and row[PARTYAB] != '':\n",
    "            data.append(row[PARTYAB])\n",
    "        # If no PARTYAB exists, check if this is the informal vote at given polling booth\n",
    "        elif row[PARTYNAME] == \"Informal\":\n",
    "            data.append(\"INFORMAL\")\n",
    "        # If not informal and no PARTYAB try the PARTYNAME. ''.join(row[PARTYNAME].split()) removes whitespace\n",
    "        elif row[PARTYNAME] != None and row[PARTYNAME] != '':\n",
    "            data.append(''.join(row[PARTYNAME].split()))\n",
    "        # If no PARTYAB and no PARTYNAME use candidate ID\n",
    "        else:\n",
    "            data.append(row[CANDID])\n",
    "\n",
    "        data.append(row[VOTES])\n",
    "\n",
    "        if accepting:\n",
    "            parsedData.append(data)\n",
    "    return parsedData    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the Division Results From 2022\n",
    "\n",
    "rows = getrows('PrimaryDivision.csv')\n",
    "parsedData = parseDataDivision(rows)\n",
    "combinedData = combineData(parsedData)\n",
    "Xs = convert(combinedData)\n",
    "Xs = normalise(Xs)\n",
    "\n",
    "preds = net(torch.tensor(Xs).to(device)).to(\"cpu\")\n",
    "\n",
    "rows = getrows('2CPDivision.csv')\n",
    "parsedData = parseDataDivision(rows)\n",
    "combinedData = combineData(parsedData)\n",
    "ys = convert(combinedData)\n",
    "ys = normalise(ys)\n",
    "ys = torch.tensor(ys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pollingID': 318, 'ALP': 61935, 'LP': 36459}\n",
      "tensor([0.3705, 0.0000, 0.6295, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n"
     ]
    }
   ],
   "source": [
    "print(combinedData[0])\n",
    "print(ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Correct Calls: 146\n",
      "Number Of Predictions with 2%: 79\n",
      "Number Of Correct Calls within 2%: 79\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "correct_call = 0\n",
    "within2pct = 0\n",
    "correctand2pct = 0\n",
    "for idx, they in enumerate(ys):\n",
    "    thisIsCorrect = False\n",
    "    pred = preds[idx].detach().numpy()\n",
    "    y = they.numpy()\n",
    "\n",
    "    winner = np.where(y==max(y))[0][0]\n",
    "    predWinner = np.where(pred==max(pred))[0][0]\n",
    "    if winner == predWinner:\n",
    "        correct_call +=1\n",
    "        thisIsCorrect = True\n",
    "    else:\n",
    "        thisIsCorrect = False\n",
    "    #     print(idx)\n",
    "    diff = np.absolute(pred-y)\n",
    "    isWithin2pct = (max(diff)<0.02)\n",
    "    if isWithin2pct:\n",
    "        within2pct += 1\n",
    "\n",
    "    if isWithin2pct and thisIsCorrect:\n",
    "        correctand2pct += 1    \n",
    "\n",
    "\n",
    "\n",
    "print(f\"Number Of Correct Calls: {correct_call}\")\n",
    "print(f\"Number Of Predictions with 2%: {within2pct}\")\n",
    "print(f\"Number Of Correct Calls within 2%: {correctand2pct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Balancing:\n",
    "- Number Of Correct Calls: 138\n",
    "- Number Of Predictions with 2%: 48\n",
    "- Number Of Correct Calls within 2%: 47\n",
    "\n",
    "Without Balancing:\n",
    "- Number Of Correct Calls: 132\n",
    "- Number Of Predictions with 2%: 70\n",
    "- Number Of Correct Calls within 2%: 67"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
